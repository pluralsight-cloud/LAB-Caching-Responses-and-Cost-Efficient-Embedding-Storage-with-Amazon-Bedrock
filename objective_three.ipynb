{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9771e561-a128-40d2-8ce0-a91f356786f7",
   "metadata": {},
   "source": [
    "# Caching Responses and Cost-efficient Embedding Storage with Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90371b78",
   "metadata": {},
   "source": [
    "## Objective Three: Choose an Efficient Storage Strategy for Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a78f6",
   "metadata": {},
   "source": [
    "In this hands-on walkthrough, you‚Äôll use the boto3 Python SDK to interact with Amazon Bedrock and generate text embeddings using the `amazon.titan-embed-text-v2:0` model. You‚Äôll create embeddings from a set of meal recipes and explore different storage and search strategies, including in-memory storage, FAISS for vector indexing, Amazon S3 for persistent object storage, and PostgreSQL with the pgvector extension for SQL-based similarity search. Each approach demonstrates how to store and retrieve embeddings efficiently, along with its performance characteristics and associated storage costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c6c59",
   "metadata": {},
   "source": [
    "### 1. Prepare the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4cb7d",
   "metadata": {},
   "source": [
    "This step includes the code to install the required Python packages needed for the rest of the exercise and restart the kernel to ensure the packages are properly loaded. While running, you might see some pip dependency warnings. These can be safely ignored as they won‚Äôt impact the steps we‚Äôre performing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bafa5-ba1f-49fd-bd9a-099c3df2571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -q botocore\n",
    "%pip install --upgrade -q boto3\n",
    "%pip install --upgrade -q numpy\n",
    "%pip install --upgrade -q faiss\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    display(HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\"))\n",
    "    print(\"‚úÖ Kernel restarted successfully\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to restart the kernel\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2aa284",
   "metadata": {},
   "source": [
    "In this step, you import several libraries required for embedding generation, storage, and similarity search. You use `boto3` to interact with AWS services programmatically and `json` to handle JSON formatting for requests and responses. The `faiss` library is used to build and search a vector index in memory, enabling fast similarity lookups. `numpy` is imported to handle numerical operations and vector transformations required for cosine similarity calculations. Finally, `psycopg2` is used to connect to a PostgreSQL database and interact with it when storing and querying embeddings using the pgvector extension. You also create a Bedrock client using boto3, which allows you to invoke models from the Amazon Bedrock service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import boto3\n",
    "    import json\n",
    "    import faiss\n",
    "    import numpy as np\n",
    "    import psycopg2\n",
    "    print(\"----------------------------\")\n",
    "    print(\"‚úÖ Libraries loaded successfully.\")\n",
    "except ImportError as e:\n",
    "    print(\"----------------------------\")\n",
    "    print(\"‚ùå Failed to load libraries.\")\n",
    "    print(f\"Error: {e}\")\n",
    "try:\n",
    "    client = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=\"us-east-1\"\n",
    "    )\n",
    "    print(\"‚úÖ bedrock-runtime client initialized successfully.\")\n",
    "except Exception as e:\n",
    "        print(\"‚ùå Failed to initialize bedrock-runtime client.\")\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166af2a8",
   "metadata": {},
   "source": [
    "### 2. Sample Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65271a",
   "metadata": {},
   "source": [
    "In this step you  define a set of recipes stored in a Python dictionary. Each entry in the dictionary includes the name of the recipe as the key and its full description as the value. These recipes will be used as input to generate embeddings for different storage and search scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfcbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = {\n",
    "        \"Spaghetti Carbonara\": \"\"\"Boil spaghetti. In a pan, cook pancetta until crispy.\n",
    "        Beat eggs with parmesan cheese. Combine spaghetti, pancetta, and egg mixture.\n",
    "        Stir quickly to create a creamy sauce. Serve hot.\"\"\",\n",
    "        \n",
    "        \"Chicken Curry\": \"\"\"Cook chopped onions, garlic, and ginger in oil. Add curry powder,\n",
    "        cumin, and turmeric. Stir in chicken pieces and brown them. Add tomatoes and\n",
    "        simmer until chicken is cooked through. Serve with rice.\"\"\",\n",
    "        \n",
    "        \"Vegan Salad\": \"\"\"Mix chopped kale, spinach, cherry tomatoes, and cucumbers.\n",
    "        Add avocado slices and chickpeas. Dress with lemon juice, olive oil, and salt.\"\"\",\n",
    "        \n",
    "        \"Grilled Cheese Sandwich\": \"\"\"Butter two slices of bread. Place cheddar cheese\n",
    "        between them. Grill in a pan until bread is golden and cheese is melted.\"\"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62435ed",
   "metadata": {},
   "source": [
    "### 3. Invoke Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f130e",
   "metadata": {},
   "source": [
    "This step defines the function to request Amazon Bedrock to invoke the `amazon.titan-embed-text-v2:0` model. It prepares the input text as a JSON payload, sends the request using the Bedrock client, and parses the response to extract the embedding. The resulting embedding is returned for use in storage or similarity search scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f543f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    payload = {\"inputText\": text}\n",
    "    response = client.invoke_model(\n",
    "        modelId=\"amazon.titan-embed-text-v2:0\",\n",
    "        body=json.dumps(payload),\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    result = json.loads(response['body'].read())\n",
    "    return result[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4396b9",
   "metadata": {},
   "source": [
    "### 4. Defining the Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92171404",
   "metadata": {},
   "source": [
    "This step defines a function to calculate cosine similarity between two vectors. It converts the input lists to NumPy arrays, then computes the cosine of the angle between them using the dot product and vector norms. The result is a value between -1 and 1, where higher values indicate greater similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "        vec1 = np.array(vec1)\n",
    "        vec2 = np.array(vec2)\n",
    "        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fa89c-db54-43c4-b0e5-256cde8e98b6",
   "metadata": {},
   "source": [
    "### 5. Store Embeddings in Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ac71fc",
   "metadata": {},
   "source": [
    "This step stores the recipe embeddings in memory and defines a function to perform a semantic similarity search. It generates an embedding for the input query, compares it with stored embeddings using cosine similarity, and returns the most similar recipes based on the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e1937-cc9b-4c7d-8a18-bc1212bc2d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embeddings in memory\n",
    "embedding_store = {}\n",
    "\n",
    "for name, text in recipes.items():\n",
    "    embedding = get_embedding(text)\n",
    "    embedding_store[name] = {\n",
    "        \"text\": text,\n",
    "        \"embedding\": embedding\n",
    "    }\n",
    "\n",
    "# Perform semantic similarity search\n",
    "def search_similar_recipes(query, top_k=2):\n",
    "    query_embedding = get_embedding(query)\n",
    "    results = []\n",
    "    \n",
    "    for name, data in embedding_store.items():\n",
    "        score = cosine_similarity(query_embedding, data[\"embedding\"])\n",
    "        results.append((name, score, data[\"text\"]))\n",
    "        \n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return results[:top_k]\n",
    "\n",
    "    # Run a search for Spaghetti Carbonara-like recipe\n",
    "    query = \"How do I cook spaghetti with eggs, cheese, and pancetta?\"\n",
    "    results = search_similar_recipes(query)\n",
    "\n",
    "    # Print results\n",
    "    for name, score, text in results:\n",
    "        print(f\"üîπ Recipe: {name}\")\n",
    "        print(f\"   Similarity Score: {score:.3f}\")\n",
    "        print(f\"   Description: {text.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249bb285",
   "metadata": {},
   "source": [
    "Storing embeddings in memory is fast and cost-free, making it ideal for quick lookups and small-scale applications. It avoids the complexity of setting up external storage and offers low-latency access. However, it's volatile‚Äîdata is lost when the application stops‚Äîand it doesn't scale well, as memory is limited and not suitable for storing large volumes of embeddings over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
